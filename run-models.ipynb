{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clean_datasets as mydata\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the models on the breas cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/breast-cancer-wisconsin.csv\n"
     ]
    }
   ],
   "source": [
    "bc = mydata.load_data(mydata.BREAST_COLS, mydata.BREAST_CANCER_NAME)\n",
    "pipeline = mydata.get_breast_cancer_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binalizer = LabelBinarizer()\n",
    "X = pipeline.fit_transform(bc)\n",
    "y = label_binalizer.fit_transform(bc['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(X, y):\n",
    "    strat_train_set = X[train_index], y[train_index]\n",
    "    strat_test_set = X[test_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Ytr = strat_train_set\n",
    "Xts, Yts = strat_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from keras.models import model_from_json\n",
    "from tensorflow import keras\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import CustomObjectScope\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_neural_network_model(model, name):\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    model_name = MODEL_DIR + DATASET_NAME + \"-\" + name\n",
    "    with open(model_name + \"-model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(model_name + \"-weights.h5\")\n",
    "    history = model.history.history\n",
    "    with open(model_name + \"-history\", 'wb') as file_pi:\n",
    "        pickle.dump(history, file_pi)\n",
    "        \n",
    "def load_neural_network(model_name):\n",
    "    model_name = \"neural_network\"\n",
    "    with CustomObjectScope({'GlorotUniform': glorot_uniform()}):\n",
    "        json_file = open(MODEL_DIR + DATASET_NAME + \"-\" + model_name + \"-model.json\", 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "        # load weights into new model\n",
    "        loaded_model.load_weights(MODEL_DIR + DATASET_NAME + \"-\" + model_name + \"-weights.h5\")\n",
    "        print(\"Loaded model from disk\")\n",
    "\n",
    "    #Load history\n",
    "    with open(MODEL_DIR + DATASET_NAME + \"-\" + model_name + \"-history\", 'rb') as fid:\n",
    "        loaded_history = pickle.load(fid)\n",
    "        \n",
    "    return loaded_model, loaded_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/breast_cancer-decision_tree.pkl\n",
      "models/breast_cancer-k-nearest-neighbor.pkl\n",
      "models/breast_cancer-SVM.pkl\n",
      "models/breast_cancer-ada-boost-classifier.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "MODEL_DIR =\"models/\"\n",
    "DATASET_NAME = \"breast_cancer\"\n",
    "\n",
    "# loading the classifier\n",
    "estimators =[('decision_tree', 0),\n",
    "             #('neural_network', best_nn_estimator.model), \n",
    "             ('k-nearest-neighbor', 0), \n",
    "             ('SVM', 0),\n",
    "             ('ada-boost-classifier', 0),\n",
    "            ]\n",
    "models = []\n",
    "\n",
    "for model_name, estimator in estimators:\n",
    "    \n",
    "    file_name = MODEL_DIR + DATASET_NAME + \"-\" + model_name + \".pkl\"\n",
    "    print(file_name)\n",
    "    \n",
    "    with open(file_name, 'rb') as fid:\n",
    "        model_loaded = pickle.load(fid)\n",
    "\n",
    "    models.append((model_name, model_loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "nn, his = load_neural_network(\"neural_network\")\n",
    "nn_history = his\n",
    "models.append((\"neural_network\", nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision_tree :  95.0\n",
      "k-nearest-neighbor :  93.57142857142857\n",
      "SVM :  96.42857142857143\n",
      "ada-boost-classifier :  94.28571428571428\n",
      "neural_network :  96.42857142857143\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models:\n",
    "    Ypr = model.predict(Xts)\n",
    "    Ypr = (Ypr > 0.5)\n",
    "    print(model_name, \": \", accuracy_score(Yts,Ypr)*100, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running models on credit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/crx.data\n"
     ]
    }
   ],
   "source": [
    "credit = mydata.load_data(mydata.CREDIT_COLS, mydata.CREDIT_NAME)\n",
    "pipeline = mydata.get_credit_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binalizer = LabelBinarizer()\n",
    "X = pipeline.fit_transform(credit)\n",
    "y = label_binalizer.fit_transform(credit['A16'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(X, y):\n",
    "    strat_train_set = X[train_index], y[train_index]\n",
    "    strat_test_set = X[test_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Ytr = strat_train_set\n",
    "Xts, Yts = strat_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/credit-decision_tree.pkl\n",
      "models/credit-k-nearest-neighbor.pkl\n",
      "models/credit-SVM.pkl\n",
      "models/credit-ada-boost-classifier.pkl\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR =\"models/\"\n",
    "DATASET_NAME = \"credit\"\n",
    "\n",
    "# loading the classifier\n",
    "estimators =[('decision_tree', 0),\n",
    "             #('neural_network', best_nn_estimator.model), \n",
    "             ('k-nearest-neighbor', 0), \n",
    "             ('SVM', 0),\n",
    "             ('ada-boost-classifier', 0),\n",
    "            ]\n",
    "models = []\n",
    "\n",
    "for model_name, estimator in estimators:\n",
    "    \n",
    "    file_name = MODEL_DIR + DATASET_NAME + \"-\" + model_name + \".pkl\"\n",
    "    print(file_name)\n",
    "    \n",
    "    with open(file_name, 'rb') as fid:\n",
    "        model_loaded = pickle.load(fid)\n",
    "        \n",
    "    models.append((model_name, model_loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "nn, his = load_neural_network(\"neural_network\")\n",
    "nn_history = his\n",
    "models.append((\"neural_network\", nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision_tree :  76.81159420289855\n",
      "k-nearest-neighbor :  84.78260869565217\n",
      "SVM :  81.15942028985508\n",
      "ada-boost-classifier :  80.43478260869566\n",
      "neural_network :  83.33333333333334\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models:\n",
    "    Ypr = model.predict(Xts)\n",
    "    Ypr = (Ypr > 0.5)\n",
    "    print(model_name, \": \", accuracy_score(Yts,Ypr)*100, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
